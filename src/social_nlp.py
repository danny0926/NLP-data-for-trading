"""
Social Media NLP Pipeline
é›™å±¤æƒ…ç·’åˆ†æï¼šFinTwitBERT (æœ¬åœ°å¿«é€Ÿ) â†’ Gemini Flash (æ·±åº¦æ¨ç†)

Stage 1: FinTwitBERT â€” æœ¬åœ°æ¨¡å‹ï¼Œå…è²»ï¼Œ~100ms/postï¼Œè™•ç† ~75% çš„è²¼æ–‡
Stage 2: Gemini 2.5 Flash â€” API æ·±åº¦æ¨ç†ï¼Œè™•ç†è¤‡é›œ/æ›–æ˜§è²¼æ–‡
"""

import json
import logging
import os
import re
from typing import Optional, List, Dict

from google import genai

from src.config import GOOGLE_API_KEY, GEMINI_MODEL

logger = logging.getLogger("SocialNLP")

# â”€â”€ å¸¸æ•¸ â”€â”€

GEMINI_THRESHOLD = 0.75
MAX_RETRIES = 3

CASHTAG_RE = re.compile(r'\$([A-Z]{1,5}(?:\.[A-Z]{1,2})?)\b')
CRYPTO_TICKERS = {"BTC", "ETH", "DOGE", "SHIB", "SOL", "ADA", "XRP"}

SARCASM_PATTERNS = [
    re.compile(r'"[^"]{1,30}"'),                  # "air quotes"
    re.compile(r'/s\b'),                           # Reddit /s marker
    re.compile(r'[ğŸ™„ğŸ˜’ğŸ¤¦ğŸ’€]'),                    # è«·åˆº emoji
    re.compile(
        r'\b(sure|totally|obviously|clearly|great|wonderful)\b'
        r'.{0,50}'
        r'\b(bankrupt|crash|bubble|fraud|fail)\b',
        re.IGNORECASE,
    ),
]

# â”€â”€ Stage 1: FinTwitBERT â”€â”€

_fintwit_pipeline = None
_fintwit_available = True  # False è¡¨ç¤º transformers ç„¡æ³•è¼‰å…¥ï¼Œæ°¸é èµ° Gemini


def _get_fintwit_pipeline():
    """Lazy-load FinTwitBERT æ¨¡å‹ï¼ˆé¦–æ¬¡ç´„ 10 ç§’ä¸‹è¼‰ï¼‰ã€‚"""
    global _fintwit_pipeline, _fintwit_available
    if not _fintwit_available:
        return None
    if _fintwit_pipeline is not None:
        return _fintwit_pipeline

    try:
        from transformers import pipeline as hf_pipeline
        _fintwit_pipeline = hf_pipeline(
            "text-classification",
            model="StephanAkkerman/FinTwitBERT-sentiment",
            device=-1,  # CPU only
            truncation=True,
            max_length=512,
        )
        logger.info("FinTwitBERT æ¨¡å‹è¼‰å…¥å®Œæˆ")
    except ImportError:
        logger.warning(
            "transformers / torch æœªå®‰è£ï¼ŒFinTwitBERT ä¸å¯ç”¨ï¼Œ"
            "æ‰€æœ‰è²¼æ–‡å°‡è·¯ç”±è‡³ Gemini åˆ†æ"
        )
        _fintwit_available = False
        _fintwit_pipeline = None
    except Exception as e:
        logger.warning(f"FinTwitBERT è¼‰å…¥å¤±æ•—: {e}")
        _fintwit_available = False
        _fintwit_pipeline = None

    return _fintwit_pipeline


def fast_classify(text: str) -> Dict:
    """Stage 1: æœ¬åœ° FinTwitBERT å¿«é€Ÿåˆ†é¡ã€‚"""
    pipe = _get_fintwit_pipeline()
    if pipe is None:
        return {"label": "Neutral", "score": 0.0}

    result = pipe(text, truncation=True)[0]
    label_map = {
        "Bullish": "Bullish", "Bearish": "Bearish", "Neutral": "Neutral",
        "LABEL_0": "Bearish", "LABEL_1": "Neutral", "LABEL_2": "Bullish",
    }
    return {
        "label": label_map.get(result["label"], result["label"]),
        "score": result["score"],
    }


# â”€â”€ Cashtag / Sarcasm å·¥å…· â”€â”€


def extract_cashtags(text: str) -> List[str]:
    """å¾æ–‡å­—ä¸­èƒå– $TICKER cashtagï¼Œæ’é™¤åŠ å¯†è²¨å¹£ã€‚"""
    found = CASHTAG_RE.findall(text.upper())
    return [t for t in found if t not in CRYPTO_TICKERS]


def has_sarcasm_signal(text: str) -> bool:
    """åµæ¸¬è«·åˆº/åè©±ä¿¡è™Ÿã€‚"""
    return any(p.search(text) for p in SARCASM_PATTERNS)


# â”€â”€ Routing â”€â”€


def needs_deep_analysis(fast_result: Dict, text: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦éœ€è¦ Gemini æ·±åº¦åˆ†æã€‚"""
    # FinTwitBERT ä¸å¯ç”¨æ™‚ï¼Œå…¨éƒ¨äº¤çµ¦ Gemini
    if not _fintwit_available:
        return True
    if fast_result["score"] < GEMINI_THRESHOLD:
        return True
    if has_sarcasm_signal(text):
        return True
    # ç„¡æ˜ç¢º ticker ä¸”æ–‡å­—è¼ƒé•· â†’ éœ€è¦ Gemini åšå¯¦é«”æ“·å–
    if len(extract_cashtags(text)) == 0 and len(text) > 80:
        return True
    return False


# â”€â”€ Stage 2: Gemini Prompts â”€â”€

SOCIAL_POLITICIAN_PROMPT = """ä½ æ˜¯ç¾åœ‹æ”¿æ²»-é‡‘èåˆ†æå¸«ï¼Œè§£è®€åœ‹æœƒè­°å“¡ç¤¾ç¾¤ç™¼è¨€å°è‚¡å¸‚çš„å½±éŸ¿ã€‚

## åˆ†æå°è±¡
- è­°å“¡ï¼š{name}
- å§”å“¡æœƒï¼š{committees}
- ç™¼è¨€å¹³å°ï¼š{platform}
- ç™¼è¨€æ™‚é–“ï¼š{post_time}
- åŸæ–‡ï¼š
{post_text}

## åˆ†ææ­¥é©Ÿ
1. è¡¨é¢èªç¾©ï¼šå­—é¢æ„æ€æ˜¯ä»€éº¼ï¼Ÿ
2. æ”¿ç­–æ˜ å°„ï¼šæ¶‰åŠå“ªå€‹ç”¢æ¥­/æ³•è¦ï¼Ÿï¼ˆåƒè€ƒå§”å“¡æœƒè·èƒ½ï¼‰
3. æƒ…ç·’æ ¡æ­£ï¼šæ˜¯å¦æœ‰è«·åˆºæˆ–åè©±ï¼Ÿ
4. å¸‚å ´å½±éŸ¿ï¼šå“ªäº›ä¸Šå¸‚å…¬å¸å—å½±éŸ¿ï¼Ÿæ–¹å‘ï¼Ÿ
5. ä¿¡è™Ÿå¼·åº¦ï¼šæ ¹æ“šå§”å“¡æœƒåœ°ä½è©•ä¼°å½±éŸ¿åŠ›

## è¼¸å‡ºï¼ˆåš´æ ¼ JSONï¼Œä¸å« markdownï¼‰
{{"sentiment": "Bullish" | "Bearish" | "Neutral", "confidence": 0.0-1.0, "signal_type": "POLICY_SIGNAL" | "TRADE_SIGNAL" | "PERSONAL_OPINION", "sarcasm_detected": false, "tickers_explicit": [], "tickers_implied": [], "sector": "", "impact_score": 1-10, "reasoning": ""}}
"""

SOCIAL_KOL_PROMPT = """ä½ æ˜¯åˆ†æç§‘æŠ€å¯Œè±ªå’Œæ„è¦‹é ˜è¢–ç¤¾ç¾¤ç™¼è¨€çš„é‡‘èåˆ†æå¸«ã€‚

## åˆ†æå°è±¡
- ç™¼è¨€è€…ï¼š{name}
- å½±éŸ¿åŠ›ï¼š{influence_profile}
- å·²çŸ¥é—œè¯ tickerï¼š{key_tickers}
- å¹³å°ï¼š{platform}
- åŸæ–‡ï¼š
{post_text}

## KOL è§£è®€è¦å‰‡
1. ğŸš€/ğŸŒ™ = å¼·çƒˆçœ‹æ¼²; ğŸ’€ = çœ‹è·Œ
2. "To the Moon" "HODL" = çœ‹æ¼²ç‰¹å®šè³‡ç”¢
3. "Something big coming" = æ­£é¢å‚¬åŒ–åŠ‘
4. å¦èªè³£å‡º = å†ç¢ºèªçœ‹å¤š
5. æ”»æ“Šç«¶çˆ­å°æ‰‹ = å°æ–¹ Bearish
{contrarian_note}

## è¼¸å‡ºï¼ˆåš´æ ¼ JSONï¼Œä¸å« markdownï¼‰
{{"sentiment": "Bullish" | "Bearish" | "Neutral", "confidence": 0.0-1.0, "signal_type": "ENDORSEMENT" | "PRODUCT_HINT" | "ATTACK" | "MEME" | "POLICY_ALIGNMENT", "sarcasm_detected": false, "tickers_explicit": [], "tickers_implied": [], "sector": "", "impact_score": 1-10, "reasoning": ""}}
"""

CRAMER_CONTRARIAN_NOTE = """
âš ï¸ æ­¤äººç‰©ç‚ºå·²çŸ¥åå‘æŒ‡æ¨™ã€‚Inverse Cramer æ•ˆæ‡‰ï¼šæ¨è–¦å¾Œ 30 å¤©å¹³å‡ -5%ã€‚
sentiment æ‡‰åè½‰ï¼šä»–æ¨è–¦ = Bearishï¼Œä»–çœ‹å£ = Bullishã€‚
"""


# â”€â”€ Gemini Client â”€â”€


class _GeminiClient:
    """Lazy-init Gemini clientï¼Œé‡è¤‡ä½¿ç”¨åŒä¸€å¯¦ä¾‹ã€‚"""

    def __init__(self):
        self._client = None  # type: Optional[genai.Client]

    @property
    def client(self) -> genai.Client:
        if self._client is None:
            api_key = GOOGLE_API_KEY or os.getenv("GOOGLE_API_KEY", "")
            if not api_key:
                raise ValueError("GOOGLE_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")
            self._client = genai.Client(api_key=api_key)
        return self._client


_gemini = _GeminiClient()


def _extract_json(text: str) -> Optional[dict]:
    """å¾ LLM è¼¸å‡ºä¸­èƒå– JSONï¼ˆæ²¿ç”¨ discovery_engine_v4 é‚è¼¯ï¼‰ã€‚"""
    if not text:
        return None
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```\s*', '', text)
    json_match = re.search(r'(\{.*\}|\[.*\])', text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(0))
        except json.JSONDecodeError:
            try:
                cleaned = re.sub(r',\s*([\]}])', r'\1', json_match.group(0))
                return json.loads(cleaned)
            except json.JSONDecodeError:
                return None
    return None


def _call_gemini(prompt: str, model: Optional[str] = None) -> str:
    """å‘¼å« Gemini APIï¼Œå›å‚³åŸå§‹æ–‡å­—ã€‚"""
    model = model or GEMINI_MODEL
    try:
        response = _gemini.client.models.generate_content(
            model=model,
            contents=prompt,
        )
        return response.text or ""
    except Exception as e:
        logger.error(f"Gemini API éŒ¯èª¤: {e}")
        return ""


# â”€â”€ Stage 2: Gemini æ·±åº¦åˆ†æ â”€â”€


def _gemini_analyze(post: Dict, targets_config: Dict) -> Dict:
    """ä½¿ç”¨ Gemini æ·±åº¦åˆ†æå–®ç¯‡è²¼æ–‡ï¼Œå›å‚³ä¿¡è™Ÿ dictã€‚"""
    author = post["author_name"]
    author_type = post["author_type"]

    # å–å¾—è©²ä½œè€…çš„è¨­å®š
    target_info = targets_config.get(author, {})

    if author_type == "politician":
        prompt = SOCIAL_POLITICIAN_PROMPT.format(
            name=author,
            committees=target_info.get("committees", "æœªçŸ¥"),
            platform=post.get("platform", "unknown"),
            post_time=post.get("post_time", ""),
            post_text=post["post_text"],
        )
    else:
        # KOL / influencer
        # Jim Cramer åå‘æŒ‡æ¨™
        is_cramer = "cramer" in author.lower()
        contrarian_note = CRAMER_CONTRARIAN_NOTE if is_cramer else ""

        prompt = SOCIAL_KOL_PROMPT.format(
            name=author,
            influence_profile=target_info.get("influence_profile", "ç§‘æŠ€/é‡‘èæ„è¦‹é ˜è¢–"),
            key_tickers=json.dumps(target_info.get("key_tickers", [])),
            platform=post.get("platform", "unknown"),
            post_text=post["post_text"],
            contrarian_note=contrarian_note,
        )

    # å‘¼å« Geminiï¼ˆå«é‡è©¦ï¼‰
    result_dict = None
    for attempt in range(MAX_RETRIES):
        raw_output = _call_gemini(prompt)
        result_dict = _extract_json(raw_output)
        if result_dict and isinstance(result_dict, dict):
            break
        logger.warning(f"Gemini JSON è§£æå¤±æ•— (attempt {attempt + 1}/{MAX_RETRIES})")
        prompt += "\n\n[é‡è¦] ä¸Šæ¬¡è¼¸å‡ºç„¡æ³•è§£æç‚º JSONï¼Œè«‹åš´æ ¼è¼¸å‡ºç´” JSON æ ¼å¼ã€‚"

    if not result_dict or not isinstance(result_dict, dict):
        logger.error(f"Gemini åˆ†æå¤±æ•—: {author} â€” å›å‚³é è¨­å€¼")
        return {
            "sentiment": "Neutral",
            "sentiment_score": 0.0,
            "signal_type": "UNKNOWN",
            "sarcasm_detected": 0,
            "tickers_explicit": "[]",
            "tickers_implied": "[]",
            "sector": "",
            "impact_score": 1.0,
            "reasoning": "Gemini åˆ†æå¤±æ•—ï¼Œç„¡æ³•è§£æå›æ‡‰",
        }

    # æ­£è¦åŒ–ç‚º social_signals è¡¨æ ¼å¼
    return {
        "sentiment": result_dict.get("sentiment", "Neutral"),
        "sentiment_score": result_dict.get("confidence", 0.0),
        "signal_type": result_dict.get("signal_type", "UNKNOWN"),
        "sarcasm_detected": 1 if result_dict.get("sarcasm_detected") else 0,
        "tickers_explicit": json.dumps(result_dict.get("tickers_explicit", [])),
        "tickers_implied": json.dumps(result_dict.get("tickers_implied", [])),
        "sector": result_dict.get("sector", ""),
        "impact_score": result_dict.get("impact_score", 5.0),
        "reasoning": result_dict.get("reasoning", ""),
    }


# â”€â”€ ä¸»å…¥å£ â”€â”€


def analyze_posts(posts: List[Dict], targets_config: Dict) -> List[Dict]:
    """
    æ‰¹æ¬¡åˆ†æç¤¾ç¾¤è²¼æ–‡ã€‚

    Args:
        posts: è²¼æ–‡åˆ—è¡¨ï¼Œæ¯ç­†éœ€åŒ…å« post_text, author_name, author_type, platform ç­‰æ¬„ä½
        targets_config: ç›®æ¨™äººç‰©è¨­å®š dictï¼ˆkey=äººåï¼Œvalue=è¨­å®šå¦‚ committees, key_tickers ç­‰ï¼‰

    Returns:
        ä¿¡è™Ÿåˆ—è¡¨ï¼Œæ¯ç­†å°æ‡‰ social_signals è¡¨çš„ä¸€åˆ—
    """
    signals = []
    gemini_count = 0
    fintwit_count = 0

    for post in posts:
        text = post.get("post_text", "")
        if not text.strip():
            continue

        # Stage 1: å¿«é€Ÿåˆ†é¡
        fast_result = fast_classify(text)

        # Stage 2 è·¯ç”±åˆ¤æ–·
        if needs_deep_analysis(fast_result, text):
            signal = _gemini_analyze(post, targets_config)
            signal["analysis_model"] = "gemini_flash"
            gemini_count += 1
        else:
            # Stage 1 çµæœç›´æ¥è¼¸å‡º
            signal = {
                "sentiment": fast_result["label"],
                "sentiment_score": fast_result["score"],
                "signal_type": "UNKNOWN",
                "sarcasm_detected": 0,
                "tickers_explicit": json.dumps(extract_cashtags(text)),
                "tickers_implied": "[]",
                "sector": "",
                "impact_score": 5.0,
                "reasoning": f"FinTwitBERT classification (confidence: {fast_result['score']:.2f})",
                "analysis_model": "fintwit_bert",
            }
            fintwit_count += 1

        # é™„åŠ è²¼æ–‡ metadata
        signal["post_id"] = post.get("db_id")
        signal["author_name"] = post["author_name"]
        signal["author_type"] = post["author_type"]
        signal["platform"] = post.get("platform", "unknown")

        signals.append(signal)

    logger.info(
        f"åˆ†æå®Œæˆ: {len(signals)} ç¯‡ "
        f"(FinTwitBERT: {fintwit_count}, Gemini: {gemini_count})"
    )
    return signals
